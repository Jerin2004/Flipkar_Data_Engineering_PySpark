Flipkart Data Engineering Project ğŸš€
This project is a Data Engineering Pipeline built using Apache Spark (PySpark) on Databricks, designed to handle and analyze Flipkart product data.
It demonstrates real-world data engineering concepts such as data ingestion, cleaning, transformation, and basic analytics at scale.

ğŸ“‚ Project Workflow
Data Ingestion:
Load Flipkart dataset into a PySpark DataFrame on Databricks.

Data Cleaning:

Handled null values and duplicates.

Corrected inconsistent data types.

Data Transformation:

Filtered records based on conditions.

Performed groupings and aggregations.

Basic Analysis:

Extracted insights such as top-rated products, brand-wise product counts, etc.

ğŸ› ï¸ Technologies Used
Apache Spark (PySpark)

Databricks Platform

Python 3

Notebook Interface (Databricks Workspace)

ğŸ§  Key Learnings
Practical exposure to distributed data processing with PySpark.

Hands-on experience with Databricks notebooks and Spark DataFrames.

Implemented real-world data cleaning, transformation, and aggregation techniques.

ğŸš€ How to Run
Clone the repository:

bash
Copy
Edit
git clone https://github.com/Jerin2004/Flipkar_Data_Engineering_PySpark
Import the notebook into your Databricks Workspace.

Attach the notebook to a running cluster.

Run all cells sequentially.

Note: Make sure your Databricks cluster has access to PySpark (comes by default).

ğŸ“¸ Sample Outputs
List of Top 10 best-rated products.

Count of products listed per brand.

Filtered list of affordable and high-rated products.

ğŸ™Œ Acknowledgments
This project was developed as a practice exercise to enhance Data Engineering skills, PySpark proficiency, and to get hands-on experience working with Databricks.
