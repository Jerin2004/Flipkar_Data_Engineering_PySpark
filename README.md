Flipkart Data Engineering Project 🚀
This project is a Data Engineering Pipeline built using Apache Spark (PySpark) on Databricks, designed to handle and analyze Flipkart product data.
It demonstrates real-world data engineering concepts such as data ingestion, cleaning, transformation, and basic analytics at scale.

📂 Project Workflow
Data Ingestion:
Load Flipkart dataset into a PySpark DataFrame on Databricks.

Data Cleaning:

Handled null values and duplicates.

Corrected inconsistent data types.

Data Transformation:

Filtered records based on conditions.

Performed groupings and aggregations.

Basic Analysis:

Extracted insights such as top-rated products, brand-wise product counts, etc.

🛠️ Technologies Used
Apache Spark (PySpark)

Databricks Platform

Python 3

Notebook Interface (Databricks Workspace)

🧠 Key Learnings
Practical exposure to distributed data processing with PySpark.

Hands-on experience with Databricks notebooks and Spark DataFrames.

Implemented real-world data cleaning, transformation, and aggregation techniques.

🚀 How to Run
Clone the repository:

bash
Copy
Edit
git clone https://github.com/Jerin2004/Flipkar_Data_Engineering_PySpark
Import the notebook into your Databricks Workspace.

Attach the notebook to a running cluster.

Run all cells sequentially.

Note: Make sure your Databricks cluster has access to PySpark (comes by default).

📸 Sample Outputs
List of Top 10 best-rated products.

Count of products listed per brand.

Filtered list of affordable and high-rated products.

🙌 Acknowledgments
This project was developed as a practice exercise to enhance Data Engineering skills, PySpark proficiency, and to get hands-on experience working with Databricks.
